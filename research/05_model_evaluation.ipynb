{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T17:55:50.379426600Z",
     "start_time": "2023-11-23T17:55:50.327776200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "      root_dir: Path\n",
    "      data_path: Path\n",
    "      model_path: Path\n",
    "      tokenizer_path: Path\n",
    "      metric_file_name: Path\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T19:23:38.046851700Z",
     "start_time": "2023-11-23T19:23:38.021854900Z"
    }
   },
   "id": "225148f08cc44ca0"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#config\n",
    "#configuration manager\n",
    "#Config\n",
    "from TextSummarizer.constants import *\n",
    "from TextSummarizer.utils.common import read_yaml,create_directory\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directory([self.config.artifact_root])\n",
    "        \n",
    "    def model_evaluation_config(self) ->ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        create_directory([config.root_dir])\n",
    "        model_evaluation_config = ModelEvaluationConfig(root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            model_path = config.model_path,\n",
    "            tokenizer_path = config.tokenizer_path,\n",
    "            metric_file_name = config.metric_file_name)\n",
    "        return model_evaluation_config\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T19:31:24.363915100Z",
     "start_time": "2023-11-23T19:31:24.341349100Z"
    }
   },
   "id": "5d8869b919d03beb"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#component\n",
    "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer\n",
    "from datasets import load_from_disk,load_metric,load_dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T19:31:25.360333400Z",
     "start_time": "2023-11-23T19:31:25.289335800Z"
    }
   },
   "id": "832832f6b88daf32"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T19:31:25.661333200Z",
     "start_time": "2023-11-23T19:31:25.636332900Z"
    }
   },
   "id": "7d5998f3f4d8c0f3"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self,config:ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    # Evaluation\n",
    "\n",
    "    def generate_batch_sized_chunks(self,list_of_elements, batch_size):\n",
    "        \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "        Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "        for i in range(0, len(list_of_elements), batch_size):\n",
    "            yield list_of_elements[i : i + batch_size]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def calculate_metric_on_test_ds(self,dataset, metric, model, tokenizer,\n",
    "                                   batch_size=16, device=device,\n",
    "                                   column_text=\"article\",\n",
    "                                   column_summary=\"highlights\"):\n",
    "        article_batches = list(self.generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
    "        target_batches = list(self.generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
    "    \n",
    "        for article_batch, target_batch in tqdm(\n",
    "            zip(article_batches, target_batches), total=len(article_batches)):\n",
    "    \n",
    "            inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                            padding=\"max_length\", return_tensors=\"pt\")\n",
    "    \n",
    "            summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                             attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                             length_penalty=0.8, num_beams=8, max_length=128)\n",
    "            ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n",
    "    \n",
    "            # Finally, we decode the generated texts,\n",
    "            # replace the  token, and add the decoded texts with the references to the metric.\n",
    "            decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                    clean_up_tokenization_spaces=True)\n",
    "                   for s in summaries]\n",
    "    \n",
    "            decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "    \n",
    "    \n",
    "            metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "    \n",
    "        #  Finally compute and return the ROUGE scores.\n",
    "        score = metric.compute()\n",
    "        return score\n",
    "    \n",
    "    def evaluate(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path)\n",
    "        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_path).to(device)\n",
    "        dataset_samsum_pt = load_from_disk(self.config.data_path)\n",
    "        \n",
    "        rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "        rouge_metric = load_metric('rouge')\n",
    "        score = self.calculate_metric_on_test_ds(\n",
    "        dataset_samsum_pt['test'][0:10], rouge_metric, model_pegasus, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",
    "    )\n",
    "    \n",
    "        rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "    \n",
    "        df = pd.DataFrame(rouge_dict, index = ['pegasus'])\n",
    "        df.to_csv(self.config.metric_file_name,index=False)\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T19:31:26.244338900Z",
     "start_time": "2023-11-23T19:31:26.228336800Z"
    }
   },
   "id": "9eecdf18746a3376"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-23 20:31:26,714: INFO: common: Directory Artifacts created]\n",
      "[2023-11-23 20:31:26,716: INFO: common: Directory Artifacts/model_evaluation created]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory Artifacts/model_trainer/pegasus-samsum-model.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m     model_evaluation\u001B[38;5;241m.\u001B[39mevaluate()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e \n",
      "Cell \u001B[1;32mIn[20], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m     model_evaluation_config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mmodel_evaluation_config()\n\u001B[0;32m      5\u001B[0m     model_evaluation \u001B[38;5;241m=\u001B[39m ModelEvaluation(model_evaluation_config)\n\u001B[1;32m----> 6\u001B[0m     \u001B[43mmodel_evaluation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e \n",
      "Cell \u001B[1;32mIn[19], line 51\u001B[0m, in \u001B[0;36mModelEvaluation.evaluate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     49\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     50\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtokenizer_path)\n\u001B[1;32m---> 51\u001B[0m model_pegasus \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForSeq2SeqLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     52\u001B[0m dataset_samsum_pt \u001B[38;5;241m=\u001B[39m load_from_disk(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdata_path)\n\u001B[0;32m     54\u001B[0m rouge_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrouge1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrouge2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrougeL\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrougeLsum\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Main-NLP-PROJECTS\\Text-Summarization-Project\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    564\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    565\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[1;32m--> 566\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    567\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    568\u001B[0m     )\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    572\u001B[0m )\n",
      "File \u001B[1;32m~\\Desktop\\Main-NLP-PROJECTS\\Text-Summarization-Project\\lib\\site-packages\\transformers\\modeling_utils.py:2992\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   2987\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m   2988\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError no file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m found in directory\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2989\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2990\u001B[0m         )\n\u001B[0;32m   2991\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2992\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m   2993\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError no file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF2_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2994\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF_WEIGHTS_NAME\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.index\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mFLAX_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m found in directory\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2995\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2996\u001B[0m         )\n\u001B[0;32m   2997\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(subfolder, pretrained_model_name_or_path)):\n\u001B[0;32m   2998\u001B[0m     archive_file \u001B[38;5;241m=\u001B[39m pretrained_model_name_or_path\n",
      "\u001B[1;31mOSError\u001B[0m: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory Artifacts/model_trainer/pegasus-samsum-model."
     ]
    }
   ],
   "source": [
    "#pipeline\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.model_evaluation_config()\n",
    "    model_evaluation = ModelEvaluation(model_evaluation_config)\n",
    "    model_evaluation.evaluate()\n",
    "except Exception as e:\n",
    "    raise e "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T19:31:30.323752Z",
     "start_time": "2023-11-23T19:31:26.713334300Z"
    }
   },
   "id": "ff30c23f0102b852"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "22d5b69eb3b280dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ad30bf289be3b14e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
